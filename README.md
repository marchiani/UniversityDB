# Database management system project
 ### Original document was created in Ukrainian and can be found in README-URK
 <br/>

## Participants:
* Boichenko Dmytro (Team Lead)
* Andrianov Nikita
* Grisiuk Mikhail
* Chornomorets Vladislav
* Matviychuk Andriy
 
# DBMS definition.
**A database management system** (*[DBMS](https://searchsqlserver.techtarget.com/definition/database-management-system)*) is a software for creating and managing databases. A DBMS provides users and programmers with a systematic way to create, retrieve, update, and manage data. 

![](https://itknowledgeexchange.techtarget.com/overheard/files/2015/01/DBMS-database-management-system.png)

A **DBMS** allows end users to create, read, update, and delete data in a database. It's essentially serves as an interface between the database and end users or applications, ensuring that data is organized consistently and readily available.

# Data life cycle
![](https://roaringelephant.org/wp-content/uploads/sites/5/2019/01/lifecycle-management.png)

** A data life cycle (*[Data life cycle](https://whatis.techtarget.com/definition/data-life-cycle)*) is the sequence of stages through which a piece of data passes from its initial generation or capture to its eventual archiving and/or disposal at the end of its useful life. 

While specifics vary, data management professionals often identify six or more stages in the data lifecycle. Here is one example:

1. *Generation or capture*. In this phase, data enters the organization, typically through data entry, receipt from an external source, or reception of a signal, such as transmitted data sensors.

2. Maintenance. In this phase, the data is processed before it is used. Data may be subjected to processes such as integration, cleaning, and extract-transformation loading.

3. active use. In this phase, the data is used to support the organization's goals and operations.

4. publication. In this phase, the data is not necessarily made available to the general public, but is simply sent outside the organization. Publication may or may not be part of the life cycle for a particular data item.

5. archiving. In this phase, the data is removed from all active production environments. It is no longer processed, used, or published, but is stored in case it is needed again in the future.

6. clean. In this phase, every copy of the data is deleted. As a rule, this is performed on data that is already archived.

Data lifecycle management is becoming increasingly important after the explosion of big data and the continuous development of the Internet of Things. Huge amounts of data are generated by the growing number of devices around the world. Proper oversight of data throughout its lifecycle is essential to optimize its usefulness and minimize the potential for errors. Finally, archiving or deleting data at the end of its useful life ensures that it does not consume more resources than necessary.

# Data Source
![][image1]
![][image2]

[image1]: https://upload.wikimedia.org/wikipedia/commons/7/77/Icon_New_File_256x256.png
[image2]: https://upload.wikimedia.org/wikipedia/commons/e/e2/Spreadsheet.png

A **Data Source** (*[Data Source](https://www.techopedia.com/definition/30323/data-source)*) in the context of computer science and computer programs is the place where the data that is used comes from. In a database management system, the main data source is the database, which can be located on a disk or a remote server. The data source for a computer program can be a file, a data description, a spreadsheet, an XML file, or even hard-coded data within the program.

Data sources can vary depending on the application or industry. Computer programs can have multiple data sources, depending on their purpose and function. Applications such as relational database management systems and even websites use databases as their primary data sources. Hardware, such as input devices and sensors, use the environment as their primary data source. A good example is a temperature and pressure monitoring system for a fluid circulation system, such as those used in factories and in refineries, which take all the related data from the environment or whatever it is; therefore, the data source here is the environment. Data such as fluid temperature and pressure are taken by sensors on a regular basis and then stored in a database.

A data source is most often used in context with databases and database management systems or any system that primarily deals with data and is called a data source name (DSN) that is defined in the application so that it can find the location of the data. It simply means what the words mean: where the data comes from.

Translated with www.DeepL.com/Translator (free version)


# Data set
![](http://docs.akana.com/ev/envision_reference/images/env_intro_dataset1.jpg)

**A data set (*[Data set](https://en.wikipedia.org/wiki/Data_set)*) is a collection of similar data used in machine data processing tasks.

Most often, a data set corresponds to the contents of a single database table or a statistical data matrix, where each of the table columns contains homogeneous values, and each of the table rows corresponds to a specific member of the data set.

The term dataset is also used to refer to data in a collection of closely related tables, images, etc. that describe the results of a particular experiment or event. Examples of this type are datasets collected by space agencies performing experiments with instruments aboard a space probe or images transmitted from space.

Some datasets are widely used in academic circles as test sets to validate the results of scientific research.

## DDF
## Introduction to DDF
**[DDF](https://open-numbers.github.io/ddf.html)** is a data model for the collaborative harmonization of multivariate statistics.
* A DDF is a data model, which means it describes how data is organized and how parts of the data relate to each other.
* Reconciliation** DDF can be used to reconcile data, meaning it can combine data from different sources into integrated, consistent, and unambiguous data sets. DDF supports a practical workflow that results in easy maintenance and an ever-growing collection of comparable data.
** **Working Together** DDF is a common data model in Open Numbers. Open Numbers is an initiative to collect and harmonize global data.
** **Multidimensional statistics** DDF is designed to store statistics with multiple dimensions. For example, population in a country and year, as well as by country, year, gender, and age group.

## DDF universe
To use DDF effectively, it comes with data formats and a query language.

### Model: DDF
As mentioned above, DDF is a data model. It is a system for organizing data and defining how pieces of data relate to each other. The DDF itself does not define the format in which the data is stored. It does not matter whether it is stored in csv files, a SQL database or a database. In other words: DDF is a conceptual model.

### Formats: DDFcsv and DDFmongo
However, a conceptual model is not enough for pragmatic use.  DDF needs a data format. Two formats have been defined for two different purposes: DDFcsv and DDFmongo .
**DDFcsv** is a tabular representation of DDF data in the well-known comma-separated value (csv) format. DDFcsv is easy to work with for people who are familiar with tabular data and allows for easy transformation from other tabular models to DDF. It is designed to be readable by both humans and machines. It is the format used in Open Issues.
** **DDFmongo** is a representation of a DDF document in a mongo database. This is used for the Gapminder tool page. This format is not yet documented.
In the future, it is possible that DDF will be represented in other formats for different purposes.

## DDFcsv
DDF is the data model used by the Gapminder Foundation to structure its data as part of the Open Numbers Initiative. The data model can be represented in many ways. Currently, it is presented both in a document format called DDFmongo and in a csv table format called DDFcsv.

### File path
The data points, entities, concepts, and metadata that can be found in the files are defined in the resources section of the datapackage.json file. This is the entry point for any machine that wants to explore the dataset. This file will always be named: datapackage.json and should be placed in the root folder of the dataset.

The file names in this document are for guidance only. This ensures consistent, systematic naming of the files in each DDF dataset, making them easy to understand and explore by anyone new to the dataset. It also allows you to automatically create a datapackage.json file using one of our tools.

### File structure
All DDFcsv files containing data start with
	
	ddf-- <collection
	
Where.

	<collection> is the collection of data that this file contains. It can be one and only one of: data points, entities, concepts, or metadata.
	
DDFcsv files must be placed in the root directory or in a subdirectory of the root of the dataset. However, they cannot be placed in the /lang/ directory. This directory is reserved for translations.

Files in csv format with a mandatory header line in the first line. The encoding must be UTF-8. Missing or unavailable data should be represented by an empty field.

All data in DDF is represented by key-value pairs. One file can contain data with only one key. Different collections never have the same key.

Different collections can never be in the same file.

Translated with www.DeepL.com/Translator (free version)


## DataPoints

A DataPoint is a pair of key values that stores how indicators change in different dimensions. For example, how the population changes by year and country.

### File name
Data points in DDFcsv are stored in files named with the following pattern:
	
	ddf--datapoints--<indicators>--by--<dimensions>.csv

Where.

	<indicators> is a list of indicators in this file.
	<dimensions> is a list of dimensions in this file.

Each parameter in the list of dimensions has the following pattern:
	
	<dimension>[-<values>]

Where

	<dimension> - the concept of this dimension.
	<values> is an exhaustive list of values for that dimension found in this file.

For example:

	ddf--datapoints--population--by--geo--year.csv
	ddf--datapoints--gdp--gdp_per_cap--by--geo--year--gender.csv
  	ddf--datapoints--population--by--geo-usa-swe--year.csv
  	ddf--datapoints--population--by--geo--year-2000.csv
  	ddf--datapoints--population--by--geo-ukr--year-2001.csv

### File structure
DataPoints are pairs of key values with one or more dimensions (key) and one indicator (value).

The general rule of only one key per file also applies to DataPoints. A single file can only contain DataPoints with the same single key, i.e. the same set of dimensions. For these dimensions, there may be multiple indicators in one file, as they are not part of the key.

#Open Data

**Open Data (https://uk.wikipedia.org/wiki/Відкриті_дані) is a concept that states that certain data should be free for use and distribution by anyone, subject to the attribution rules of a share-alike license.

The concept of data openness is not new, but it has become widespread with the development of information technology and the Internet.

Among the set of open data, special attention is paid to open government data as a tool for assessing and monitoring the work of the government and the state, which is part of the e-government model.

In many countries, the development of open government data has been supported at the state level for a long time. This process includes the creation of an appropriate legislative framework, executive bodies and information resources.

### USA
<img src="https://upload.wikimedia.org/wikipedia/commons/a/a4/Flag_of_the_United_States.svg" alt="USA" width="400"/>

In the United States, the targeted development of open government data began in 2009 with the creation of the [Data.gov] resource (https://uk.wikipedia.org/wiki/Data.gov) and the publication of the US Open Government Directive. In turn, these initiatives were a continuation of the US e-government development policy [https://uk.wikipedia.org/wiki/%D0%95%D0%BB%D0%B5%D0%BA%D1%82%D1%80%D0%BE%D0%BD%D0%BD%D0%B8%D0%B9_%D1%83%D1%80%D1%8F%D0%B4], which has been implemented since 2002.

### European Union
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Flag_of_Europe.svg/1024px-Flag_of_Europe.svg.png" alt="European Union" width="400"/>

In Europe, along with national programs, there are many pan-European programs to support and develop open data and related resources funded by the EU. Here we can mention the DOPA projects, which are being developed under the [Seventh Framework Program](https://cordis.europa.eu/fp7/home_en.html) of the [European Commission](https://uk.wikipedia.org/wiki/%D0%84%D0%B2%D1%80%D0%BE%D0%BF%D0%B5%D0%B9%D1%81%D1%8C%D0%BA%D0%B0_%D0%BA%D0%BE%D0%BC%D1%96%D1%81%D1%96%D1%8F).

### Russia
<img src="https://upload.wikimedia.org/wikipedia/commons/f/f3/Flag_of_Russia.svg" alt="Russia" width="400"/>

As for the CIS countries and Ukraine in particular, Russia is the most active in this area.

In the summer of 2013, it adopted [Federal Law No. 112-FZ](https://web.archive.org/web/20140804152026/http://xn--d1abbgf6aiiy.xn--p1ai/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/18302), which introduces the concept of open data and defines the procedure for its publication on state resources.

# Examples of Open Databases
Today, an important part for the existence and promotion of data is a database, also known as a DBMS. With its help, most businesses, companies and organizations analyze some information to predict a certain result.
One such database can be **Google Dataset Search**. This engine provides the necessary **tool** to find **OPEN** Databases.

![](https://i.ibb.co/Y0tysqZ/1.png)

For example, we can find out information on the infant mortality rate in Ukraine, which is publicly available to any user.

![](https://i.ibb.co/Zfchh3T/2.png)

As we can see, **Google Dataset Search** provides us with access to several databases that are linked by a common theme. The user is given the opportunity to choose the database he needs by several parameters.

![](https://i.ibb.co/Qc4sYyz/3.png)

Translated with www.DeepL.com/Translator (free version)



Перейшовши за необхідним посиланням [Україна - коефіцієнт смертності дітей](https://knoema.ru/atlas/%D0%A3%D0%BA%D1%80%D0%B0%D0%B8%D0%BD%D0%B0/topics/%D0%97%D0%B4%D1%80%D0%B0%D0%B2%D0%BE%D0%BE%D1%85%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5/%D0%A1%D0%BE%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5-%D0%B7%D0%B4%D0%BE%D1%80%D0%BE%D0%B2%D1%8C%D1%8F/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82-%D0%BC%D0%BB%D0%B0%D0%B4%D0%B5%D0%BD%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9-%D1%81%D0%BC%D0%B5%D1%80%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B8) 
we get to the site that shows the most necessary information at our request. This data can be presented in the form of some tables, diagrams, charts, etc.

![](https://i.ibb.co/KDfnKCd/4.png)

Thanks to this format of data storage, the user can easily understand the situation and evaluate the data he needs.
>If we go to their main site and open the **[Databases](https://knoema.ru/atlas)** tab, we will be provided with a complete list of all possible sources of information from which the necessary data with the necessary schemes were taken. The user is also provided with a small part of the data for review.

![](https://i.ibb.co/sJTHDMg/5.png)

Such databases store information for a long time, and as a result, can be modified later to expand their functionality in the future. Also, this is not the only database that can provide access to such data. For example, we can take **[Google Public Data] (https://www.google.com/publicdata/explore?ds=d5bncppjof8f9_&hl=en_US&dl=en_US#! ctype=l&strail=false&bcs=d&nselm=h&met_y=employment&fdim_y=gdp_production_component:2&scale_y=lin&ind_y=false&rdim=region&idim=region:NAC:MEA:LCN:ECS:EAS:SAS: SSF&ifdim=region&tdim=true&hl=en_US&dl=en_US&ind=false)**, which also displays the ability to search for the required data.

![](https://i.ibb.co/VHy0dGp/6.png)

All this shows that the database relies on some sources of information, facts, experiments, etc. to more accurately predict information about a particular product. There are different databases in the world that provide data on the necessary information for different purposes. For example, as shown in the figure above, this database displays information about the statistics of products manufactured in the world or in some specific territories of the earth for a certain period of time.
>But, can only special search databases provide us with such data? NO**.

For example, such a site as **[GapMinder](https://www.gapminder.org/)** provides the user with a set of data that can be displayed in the form of interesting videos from **TedTalk** or some tools that also present information but in a more engaging style.

![](https://i.ibb.co/3FSTFfc/7.png)
